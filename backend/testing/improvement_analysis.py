"""
Comprehensive Test Results Analysis & Improvement Recommendations
Analyzes the test report to identify specific areas for improvement
"""

import json
from typing import Dict, List, Any
from datetime import datetime

def analyze_test_report(report_path: str):
    """Analyze comprehensive test report for improvement opportunities"""
    
    with open(report_path, 'r') as f:
        report = json.load(f)
    
    print("ğŸ” TIDAL STREAMLINE - TEST RESULTS ANALYSIS")
    print("=" * 60)
    print(f"ğŸ“Š Report Generated: {report['test_run_info']['start_time']}")
    print(f"ğŸ¯ Overall Score: {report['ai_analysis_summary']['summary_statistics']['overall_average_score']:.1f}/100")
    print(f"ğŸ“ˆ Score Range: {report['ai_analysis_summary']['summary_statistics']['lowest_score']} - {report['ai_analysis_summary']['summary_statistics']['highest_score']}")
    
    # Category Performance Analysis
    print("\nğŸ¯ CATEGORY PERFORMANCE ANALYSIS")
    print("-" * 40)
    
    categories = report['ai_analysis_summary']['category_performance']
    
    # Identify weakest areas
    weak_areas = []
    strong_areas = []
    
    for category, stats in categories.items():
        avg_score = stats['average']
        max_possible = stats['total_possible']
        percentage = (avg_score / max_possible) * 100
        
        if percentage < 75:
            weak_areas.append((category, percentage, avg_score, max_possible))
        elif percentage > 95:
            strong_areas.append((category, percentage, avg_score, max_possible))
        
        print(f"ğŸ“‹ {category.replace('_', ' ').title()}: {avg_score:.1f}/{max_possible} ({percentage:.1f}%)")
    
    # Priority Improvement Areas
    print("\nğŸš¨ PRIORITY IMPROVEMENT AREAS")
    print("-" * 40)
    
    if weak_areas:
        weak_areas.sort(key=lambda x: x[1])  # Sort by percentage, lowest first
        for area, pct, avg, max_val in weak_areas:
            print(f"âŒ {area.replace('_', ' ').title()}: {pct:.1f}% - NEEDS ATTENTION")
            print(f"   Current: {avg:.1f}/{max_val} | Target: >{max_val*0.8:.1f}")
    else:
        print("âœ… No critical weak areas found - all categories performing well!")
    
    # Specific Improvement Recommendations
    print("\nğŸ’¡ TOP IMPROVEMENT RECOMMENDATIONS")
    print("-" * 40)
    
    improvements = report['ai_analysis_summary'].get('common_improvements_needed', [])
    
    # Group by frequency and severity
    critical_improvements = []
    moderate_improvements = []
    
    for improvement, frequency in improvements[:10]:  # Top 10
        if 'consistency' in improvement.lower() or 'align' in improvement.lower():
            critical_improvements.append((improvement, frequency))
        else:
            moderate_improvements.append((improvement, frequency))
    
    print("ğŸ”´ CRITICAL (System Logic Issues):")
    for improvement, freq in critical_improvements:
        print(f"   â€¢ {improvement}")
        if freq > 1:
            print(f"     âš ï¸ Appears in {freq} tests")
    
    print("\nğŸŸ¡ MODERATE (Data Quality Issues):")
    for improvement, freq in moderate_improvements:
        print(f"   â€¢ {improvement}")
        if freq > 1:
            print(f"     âš ï¸ Appears in {freq} tests")
    
    # Role Category Performance
    print("\nğŸ“Š ROLE CATEGORY PERFORMANCE")
    print("-" * 40)
    
    role_performance = report['ai_analysis_summary']['role_category_performance']
    
    # Sort by performance
    role_scores = []
    for role, stats in role_performance.items():
        role_scores.append((role, stats['average_score']))
    
    role_scores.sort(key=lambda x: x[1])  # Sort by score
    
    print("ğŸ”» LOWEST PERFORMING ROLES:")
    for role, score in role_scores[:3]:
        print(f"   ğŸ“‰ {role}: {score}/100")
        if score < 85:
            print(f"      âš ï¸ Below target performance")
    
    print("\nğŸ”º TOP PERFORMING ROLES:")
    for role, score in role_scores[-3:]:
        print(f"   ğŸ“ˆ {role}: {score}/100")
    
    # Generate Action Plan
    print("\nğŸ¯ RECOMMENDED ACTION PLAN")
    print("-" * 40)
    
    action_items = []
    
    # Based on category analysis
    if any('logical_consistency' in cat for cat, _, _, _ in weak_areas):
        action_items.append({
            'priority': 'HIGH',
            'category': 'System Logic',
            'action': 'Fix regional recommendations alignment with market insights',
            'impact': 'Improve logical consistency scores by 15-20%'
        })
    
    if any('salary_accuracy' in cat for cat, _, _, _ in weak_areas):
        action_items.append({
            'priority': 'HIGH', 
            'category': 'Salary Data',
            'action': 'Update US salary benchmarks and regional comparisons',
            'impact': 'Improve salary accuracy scores by 10-15%'
        })
    
    if any('regional_recommendations' in cat for cat, _, _, _ in weak_areas):
        action_items.append({
            'priority': 'MEDIUM',
            'category': 'Regional Intelligence',
            'action': 'Enhance regional demand insights and recommendations',
            'impact': 'Better regional recommendation scores'
        })
    
    # Always include data quality improvements
    action_items.append({
        'priority': 'MEDIUM',
        'category': 'Data Quality',
        'action': 'Remove skills redundancy and improve certification recommendations',
        'impact': 'Cleaner, more actionable data output'
    })
    
    # Sort by priority
    priority_order = {'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
    action_items.sort(key=lambda x: priority_order.get(x['priority'], 99))
    
    for i, item in enumerate(action_items, 1):
        priority_icon = 'ğŸ”´' if item['priority'] == 'HIGH' else 'ğŸŸ¡' if item['priority'] == 'MEDIUM' else 'ğŸŸ¢'
        print(f"\n{i}. {priority_icon} {item['priority']} PRIORITY")
        print(f"   ğŸ“‚ Category: {item['category']}")
        print(f"   ğŸ”§ Action: {item['action']}")
        print(f"   ğŸ“ˆ Expected Impact: {item['impact']}")
    
    # Performance Summary
    print("\nğŸ“ˆ PERFORMANCE SUMMARY")
    print("-" * 40)
    
    avg_score = report['ai_analysis_summary']['summary_statistics']['overall_average_score']
    
    if avg_score >= 90:
        grade = "A"
        status = "EXCELLENT"
        color = "ğŸŸ¢"
    elif avg_score >= 85:
        grade = "B+"
        status = "VERY GOOD"
        color = "ğŸ”µ"
    elif avg_score >= 80:
        grade = "B"
        status = "GOOD"
        color = "ğŸŸ¡"
    else:
        grade = "C"
        status = "NEEDS IMPROVEMENT"
        color = "ğŸ”´"
    
    print(f"{color} Overall Grade: {grade} ({status})")
    print(f"ğŸ“Š Average Score: {avg_score:.1f}/100")
    print(f"âœ… Tests Passing (>80): {report['ai_analysis_summary']['summary_statistics']['tests_above_80']}/12")
    print(f"âš¡ Average Processing Time: {report['performance_metrics']['average_execution_time']:.1f}s")
    
    print(f"\nğŸ¯ TARGET: Achieve 90+ average score across all role categories")
    print(f"ğŸ“ˆ IMPROVEMENT NEEDED: +{max(0, 90 - avg_score):.1f} points")
    
    return action_items

if __name__ == "__main__":
    report_path = "/Users/joeymuller/Documents/coding-projects/active-projects/tidal-streamline/backend/testing/comprehensive_test_report_20250820_160222.json"
    action_items = analyze_test_report(report_path)
    
    print(f"\nğŸ’¾ Analysis complete! Generated {len(action_items)} action items.")
    print("ğŸ“‹ Use this analysis to prioritize system improvements.")